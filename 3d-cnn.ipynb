{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv3D,MaxPool3D,Flatten, Dense, Reshape\n",
    "from keras.layers import Dropout, Input,BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "from operator import truediv\n",
    "\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import spectral\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'IP'\n",
    "test_ratio = 0.7\n",
    "windowSize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    \n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat('../input/hsi-dataset/Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "        labels = sio.loadmat('../input/hsi-dataset/Indian_pines_gt.mat')['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPCA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145, 145, 200), (145, 145))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30 if dataset == 'IP' else 15\n",
    "X,pca = applyPCA(X,numComponents=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10249, 25, 25, 30), (10249,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3074, 25, 25, 30), (7175, 25, 25, 30), (3074,), (7175,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOdel and traing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3074, 25, 25, 30, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3074, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = windowSize\n",
    "L = K\n",
    "output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input layer\n",
    "input_layer = Input((S, S, L, 1))\n",
    "\n",
    "## convolutional layers\n",
    "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
    "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer3)\n",
    "pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
    "flatten_layer = Flatten()(pooling_layer2) \n",
    "\n",
    "## fully connected layers\n",
    "dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model with input layer and output layer\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 25, 25, 30, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 23, 23, 24, 8)     512       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 21, 21, 20, 16)    5776      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 19, 19, 18, 32)    13856     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 9, 9, 9, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 9, 9, 32)       128       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23328)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               5972224   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 6,027,456\n",
      "Trainable params: 6,027,392\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, decay=1e-06)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3074/3074 [==============================] - 6s 2ms/step - loss: 2.0102 - accuracy: 0.5377\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.53774, saving model to best-model.hdf5\n",
      "Epoch 2/100\n",
      "3074/3074 [==============================] - 2s 575us/step - loss: 0.4566 - accuracy: 0.8559\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.53774 to 0.85589, saving model to best-model.hdf5\n",
      "Epoch 3/100\n",
      "3074/3074 [==============================] - 2s 573us/step - loss: 0.2189 - accuracy: 0.9314\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.85589 to 0.93136, saving model to best-model.hdf5\n",
      "Epoch 4/100\n",
      "3074/3074 [==============================] - 2s 564us/step - loss: 0.0988 - accuracy: 0.9681\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.93136 to 0.96812, saving model to best-model.hdf5\n",
      "Epoch 5/100\n",
      "3074/3074 [==============================] - 2s 558us/step - loss: 0.0585 - accuracy: 0.9818\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.96812 to 0.98178, saving model to best-model.hdf5\n",
      "Epoch 6/100\n",
      "3074/3074 [==============================] - 2s 575us/step - loss: 0.0484 - accuracy: 0.9828\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.98178 to 0.98276, saving model to best-model.hdf5\n",
      "Epoch 7/100\n",
      "3074/3074 [==============================] - 2s 549us/step - loss: 0.0907 - accuracy: 0.9730\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.98276\n",
      "Epoch 8/100\n",
      "3074/3074 [==============================] - 2s 549us/step - loss: 0.0693 - accuracy: 0.9805\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.98276\n",
      "Epoch 9/100\n",
      "3074/3074 [==============================] - 2s 548us/step - loss: 0.0596 - accuracy: 0.9785\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.98276\n",
      "Epoch 10/100\n",
      "3074/3074 [==============================] - 2s 548us/step - loss: 0.0464 - accuracy: 0.9880\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.98276 to 0.98796, saving model to best-model.hdf5\n",
      "Epoch 11/100\n",
      "3074/3074 [==============================] - 2s 556us/step - loss: 0.0263 - accuracy: 0.9922\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.98796 to 0.99219, saving model to best-model.hdf5\n",
      "Epoch 12/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0222 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.99219 to 0.99545, saving model to best-model.hdf5\n",
      "Epoch 13/100\n",
      "3074/3074 [==============================] - 2s 547us/step - loss: 0.0219 - accuracy: 0.9932\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.99545\n",
      "Epoch 14/100\n",
      "3074/3074 [==============================] - 2s 550us/step - loss: 0.0111 - accuracy: 0.9958\n",
      "\n",
      "Epoch 00014: accuracy improved from 0.99545 to 0.99577, saving model to best-model.hdf5\n",
      "Epoch 15/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0158 - accuracy: 0.9945\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.99577\n",
      "Epoch 16/100\n",
      "3074/3074 [==============================] - 2s 529us/step - loss: 0.0197 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.99577\n",
      "Epoch 17/100\n",
      "3074/3074 [==============================] - 2s 545us/step - loss: 0.0159 - accuracy: 0.9951\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.99577\n",
      "Epoch 18/100\n",
      "3074/3074 [==============================] - 2s 536us/step - loss: 0.0085 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00018: accuracy improved from 0.99577 to 0.99772, saving model to best-model.hdf5\n",
      "Epoch 19/100\n",
      "3074/3074 [==============================] - 2s 577us/step - loss: 0.0138 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.99772\n",
      "Epoch 20/100\n",
      "3074/3074 [==============================] - 2s 558us/step - loss: 0.0102 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.99772\n",
      "Epoch 21/100\n",
      "3074/3074 [==============================] - 2s 553us/step - loss: 0.0102 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.99772\n",
      "Epoch 22/100\n",
      "3074/3074 [==============================] - 2s 552us/step - loss: 0.0105 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.99772\n",
      "Epoch 23/100\n",
      "3074/3074 [==============================] - 2s 558us/step - loss: 0.0070 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00023: accuracy improved from 0.99772 to 0.99805, saving model to best-model.hdf5\n",
      "Epoch 24/100\n",
      "3074/3074 [==============================] - 2s 575us/step - loss: 0.0052 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: accuracy improved from 0.99805 to 0.99837, saving model to best-model.hdf5\n",
      "Epoch 25/100\n",
      "3074/3074 [==============================] - 2s 572us/step - loss: 0.0163 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.99837\n",
      "Epoch 26/100\n",
      "3074/3074 [==============================] - 2s 573us/step - loss: 0.0100 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.99837\n",
      "Epoch 27/100\n",
      "3074/3074 [==============================] - 2s 570us/step - loss: 0.0105 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.99837\n",
      "Epoch 28/100\n",
      "3074/3074 [==============================] - 2s 574us/step - loss: 0.0050 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.99837\n",
      "Epoch 29/100\n",
      "3074/3074 [==============================] - 2s 580us/step - loss: 0.0040 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.99837\n",
      "Epoch 30/100\n",
      "3074/3074 [==============================] - 2s 575us/step - loss: 0.0096 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.99837\n",
      "Epoch 31/100\n",
      "3074/3074 [==============================] - 2s 576us/step - loss: 0.0106 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.99837\n",
      "Epoch 32/100\n",
      "3074/3074 [==============================] - 2s 576us/step - loss: 0.0093 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.99837\n",
      "Epoch 33/100\n",
      "3074/3074 [==============================] - 2s 575us/step - loss: 0.0073 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.99837\n",
      "Epoch 34/100\n",
      "3074/3074 [==============================] - 2s 576us/step - loss: 0.0065 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.99837\n",
      "Epoch 35/100\n",
      "3074/3074 [==============================] - 2s 584us/step - loss: 0.0063 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.99837\n",
      "Epoch 36/100\n",
      "3074/3074 [==============================] - 2s 587us/step - loss: 0.0095 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.99837\n",
      "Epoch 37/100\n",
      "3074/3074 [==============================] - 2s 571us/step - loss: 0.0085 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.99837\n",
      "Epoch 38/100\n",
      "3074/3074 [==============================] - 2s 573us/step - loss: 0.0044 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00038: accuracy improved from 0.99837 to 0.99870, saving model to best-model.hdf5\n",
      "Epoch 39/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0077 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.99870\n",
      "Epoch 40/100\n",
      "3074/3074 [==============================] - 2s 532us/step - loss: 0.0056 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.99870\n",
      "Epoch 41/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0134 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.99870\n",
      "Epoch 42/100\n",
      "3074/3074 [==============================] - 2s 540us/step - loss: 0.0091 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.99870\n",
      "Epoch 43/100\n",
      "3074/3074 [==============================] - 2s 536us/step - loss: 0.0101 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.99870\n",
      "Epoch 44/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0103 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.99870\n",
      "Epoch 45/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0095 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.99870\n",
      "Epoch 46/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0071 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.99870\n",
      "Epoch 47/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0120 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.99870\n",
      "Epoch 48/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0037 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.99870\n",
      "Epoch 49/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0039 - accuracy: 0.9997\n",
      "\n",
      "Epoch 00049: accuracy improved from 0.99870 to 0.99967, saving model to best-model.hdf5\n",
      "Epoch 50/100\n",
      "3074/3074 [==============================] - 2s 535us/step - loss: 0.0040 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.99967\n",
      "Epoch 51/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0969 - accuracy: 0.9789\n",
      "\n",
      "Epoch 00051: accuracy did not improve from 0.99967\n",
      "Epoch 52/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0526 - accuracy: 0.9850\n",
      "\n",
      "Epoch 00052: accuracy did not improve from 0.99967\n",
      "Epoch 53/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0222 - accuracy: 0.9935\n",
      "\n",
      "Epoch 00053: accuracy did not improve from 0.99967\n",
      "Epoch 54/100\n",
      "3074/3074 [==============================] - 2s 588us/step - loss: 0.0214 - accuracy: 0.9935\n",
      "\n",
      "Epoch 00054: accuracy did not improve from 0.99967\n",
      "Epoch 55/100\n",
      "3074/3074 [==============================] - 2s 539us/step - loss: 0.0118 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00055: accuracy did not improve from 0.99967\n",
      "Epoch 56/100\n",
      "3074/3074 [==============================] - 2s 538us/step - loss: 0.0134 - accuracy: 0.9961\n",
      "\n",
      "Epoch 00056: accuracy did not improve from 0.99967\n",
      "Epoch 57/100\n",
      "3074/3074 [==============================] - 2s 547us/step - loss: 0.0131 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00057: accuracy did not improve from 0.99967\n",
      "Epoch 58/100\n",
      "3074/3074 [==============================] - 2s 541us/step - loss: 0.0152 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00058: accuracy did not improve from 0.99967\n",
      "Epoch 59/100\n",
      "3074/3074 [==============================] - 2s 536us/step - loss: 0.0076 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00059: accuracy did not improve from 0.99967\n",
      "Epoch 60/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0099 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00060: accuracy did not improve from 0.99967\n",
      "Epoch 61/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0042 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00061: accuracy did not improve from 0.99967\n",
      "Epoch 62/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0054 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00062: accuracy did not improve from 0.99967\n",
      "Epoch 63/100\n",
      "3074/3074 [==============================] - 2s 532us/step - loss: 0.0038 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00063: accuracy did not improve from 0.99967\n",
      "Epoch 64/100\n",
      "3074/3074 [==============================] - 2s 532us/step - loss: 0.0059 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00064: accuracy did not improve from 0.99967\n",
      "Epoch 65/100\n",
      "3074/3074 [==============================] - 2s 535us/step - loss: 0.0160 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00065: accuracy did not improve from 0.99967\n",
      "Epoch 66/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0024 - accuracy: 0.9997\n",
      "\n",
      "Epoch 00066: accuracy did not improve from 0.99967\n",
      "Epoch 67/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0042 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00067: accuracy did not improve from 0.99967\n",
      "Epoch 68/100\n",
      "3074/3074 [==============================] - 2s 535us/step - loss: 0.0033 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00068: accuracy did not improve from 0.99967\n",
      "Epoch 69/100\n",
      "3074/3074 [==============================] - 2s 535us/step - loss: 0.0055 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00069: accuracy did not improve from 0.99967\n",
      "Epoch 70/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0076 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00070: accuracy did not improve from 0.99967\n",
      "Epoch 71/100\n",
      "3074/3074 [==============================] - 2s 539us/step - loss: 0.0105 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00071: accuracy did not improve from 0.99967\n",
      "Epoch 72/100\n",
      "3074/3074 [==============================] - 2s 535us/step - loss: 0.0085 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00072: accuracy did not improve from 0.99967\n",
      "Epoch 73/100\n",
      "3074/3074 [==============================] - 2s 539us/step - loss: 0.0095 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00073: accuracy did not improve from 0.99967\n",
      "Epoch 74/100\n",
      "3074/3074 [==============================] - 2s 530us/step - loss: 0.0029 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00074: accuracy did not improve from 0.99967\n",
      "Epoch 75/100\n",
      "3074/3074 [==============================] - 2s 536us/step - loss: 0.0068 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00075: accuracy did not improve from 0.99967\n",
      "Epoch 76/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0108 - accuracy: 0.9971\n",
      "\n",
      "Epoch 00076: accuracy did not improve from 0.99967\n",
      "Epoch 77/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0013 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00077: accuracy did not improve from 0.99967\n",
      "Epoch 78/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0087 - accuracy: 0.9974\n",
      "\n",
      "Epoch 00078: accuracy did not improve from 0.99967\n",
      "Epoch 79/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0029 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00079: accuracy did not improve from 0.99967\n",
      "Epoch 80/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0054 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00080: accuracy did not improve from 0.99967\n",
      "Epoch 81/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0045 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00081: accuracy did not improve from 0.99967\n",
      "Epoch 82/100\n",
      "3074/3074 [==============================] - 2s 538us/step - loss: 0.0075 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00082: accuracy did not improve from 0.99967\n",
      "Epoch 83/100\n",
      "3074/3074 [==============================] - 2s 532us/step - loss: 0.0029 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00083: accuracy did not improve from 0.99967\n",
      "Epoch 84/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0069 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00084: accuracy did not improve from 0.99967\n",
      "Epoch 85/100\n",
      "3074/3074 [==============================] - 2s 535us/step - loss: 0.0064 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00085: accuracy did not improve from 0.99967\n",
      "Epoch 86/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0026 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00086: accuracy did not improve from 0.99967\n",
      "Epoch 87/100\n",
      "3074/3074 [==============================] - 2s 534us/step - loss: 0.0029 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00087: accuracy did not improve from 0.99967\n",
      "Epoch 88/100\n",
      "3074/3074 [==============================] - 2s 538us/step - loss: 0.0055 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00088: accuracy did not improve from 0.99967\n",
      "Epoch 89/100\n",
      "3074/3074 [==============================] - 2s 532us/step - loss: 0.0048 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00089: accuracy did not improve from 0.99967\n",
      "Epoch 90/100\n",
      "3074/3074 [==============================] - 2s 561us/step - loss: 0.0071 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00090: accuracy did not improve from 0.99967\n",
      "Epoch 91/100\n",
      "3074/3074 [==============================] - 2s 536us/step - loss: 0.0037 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00091: accuracy did not improve from 0.99967\n",
      "Epoch 92/100\n",
      "3074/3074 [==============================] - 2s 572us/step - loss: 0.0061 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00092: accuracy did not improve from 0.99967\n",
      "Epoch 93/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0019 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00093: accuracy did not improve from 0.99967\n",
      "Epoch 94/100\n",
      "3074/3074 [==============================] - 2s 537us/step - loss: 0.0082 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00094: accuracy did not improve from 0.99967\n",
      "Epoch 95/100\n",
      "3074/3074 [==============================] - 2s 542us/step - loss: 0.0052 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00095: accuracy did not improve from 0.99967\n",
      "Epoch 96/100\n",
      "3074/3074 [==============================] - 2s 533us/step - loss: 0.0022 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00096: accuracy did not improve from 0.99967\n",
      "Epoch 97/100\n",
      "3074/3074 [==============================] - 2s 530us/step - loss: 0.0031 - accuracy: 0.9997\n",
      "\n",
      "Epoch 00097: accuracy did not improve from 0.99967\n",
      "Epoch 98/100\n",
      "3074/3074 [==============================] - 2s 529us/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00098: accuracy did not improve from 0.99967\n",
      "Epoch 99/100\n",
      "3074/3074 [==============================] - 2s 529us/step - loss: 0.0085 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00099: accuracy did not improve from 0.99967\n",
      "Epoch 100/100\n",
      "3074/3074 [==============================] - 2s 531us/step - loss: 0.0036 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00100: accuracy did not improve from 0.99967\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size=256, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7175, 25, 25, 30, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7175, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.99      0.99      0.99      1000\n",
      "           2       0.98      0.99      0.99       581\n",
      "           3       0.99      1.00      1.00       166\n",
      "           4       0.99      0.99      0.99       338\n",
      "           5       0.99      0.99      0.99       511\n",
      "           6       1.00      1.00      1.00        20\n",
      "           7       0.99      1.00      1.00       335\n",
      "           8       0.88      1.00      0.93        14\n",
      "           9       0.99      1.00      1.00       680\n",
      "          10       1.00      1.00      1.00      1719\n",
      "          11       0.99      0.97      0.98       415\n",
      "          12       1.00      1.00      1.00       143\n",
      "          13       1.00      0.99      1.00       886\n",
      "          14       1.00      1.00      1.00       270\n",
      "          15       0.98      0.98      0.98        65\n",
      "\n",
      "    accuracy                           0.99      7175\n",
      "   macro avg       0.99      0.99      0.99      7175\n",
      "weighted avg       0.99      0.99      0.99      7175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    "\n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                        'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7175/7175 [==============================] - 2s 280us/step\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)\n",
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"classification_report.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize\n",
    "numComponents = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,pca = applyPCA(X, numComponents=numComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"predictions.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
