{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv3D,MaxPool3D,Flatten, Dense, Reshape\n",
    "from keras.layers import Dropout, Input,BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "from operator import truediv\n",
    "\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import spectral\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'IP'\n",
    "test_ratio = 0.8\n",
    "windowSize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    \n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat('../input/hsi-dataset/Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "        labels = sio.loadmat('../input/hsi-dataset/Indian_pines_gt.mat')['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyLDA(X,y):\n",
    "    newX=np.reshape(X, (-1, X.shape[2]))\n",
    "    y=np.reshape(y,(-1,1))\n",
    "    lda=LDA()\n",
    "    newX = lda.fit_transform(newX,y.ravel())\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1],newX.shape[1]))\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " X= applyLDA(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 145, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = X.shape[2]\n",
    "\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10249, 25, 25, 16), (10249,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2049, 25, 25, 16), (8200, 25, 25, 16), (2049,), (8200,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "*MODELING AND TRAINING****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 25, 25, 16, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = windowSize\n",
    "L = K\n",
    "output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input layer\n",
    "input_layer = Input((S, S, L, 1))\n",
    "\n",
    "## convolutional layers\n",
    "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
    "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer3)\n",
    "pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
    "flatten_layer = Flatten()(pooling_layer2) \n",
    "\n",
    "## fully connected layers\n",
    "dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model with input layer and output layer\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 25, 25, 16, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 23, 23, 10, 8)     512       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 21, 21, 6, 16)     5776      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 19, 19, 4, 32)     13856     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 9, 9, 2, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 9, 2, 32)       128       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1327360   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,382,592\n",
      "Trainable params: 1,382,528\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, decay=1e-06)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2049/2049 [==============================] - 5s 2ms/step - loss: 2.0118 - accuracy: 0.4202\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.42020, saving model to best-model.hdf5\n",
      "Epoch 2/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.6212 - accuracy: 0.7960\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.42020 to 0.79600, saving model to best-model.hdf5\n",
      "Epoch 3/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.2763 - accuracy: 0.9092\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.79600 to 0.90922, saving model to best-model.hdf5\n",
      "Epoch 4/100\n",
      "2049/2049 [==============================] - 0s 217us/step - loss: 0.1728 - accuracy: 0.9488\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.90922 to 0.94876, saving model to best-model.hdf5\n",
      "Epoch 5/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.1423 - accuracy: 0.9595\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.94876 to 0.95949, saving model to best-model.hdf5\n",
      "Epoch 6/100\n",
      "2049/2049 [==============================] - 0s 225us/step - loss: 0.2519 - accuracy: 0.9239\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.95949\n",
      "Epoch 7/100\n",
      "2049/2049 [==============================] - 0s 221us/step - loss: 0.2478 - accuracy: 0.9234\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.95949\n",
      "Epoch 8/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.2179 - accuracy: 0.9395\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.95949\n",
      "Epoch 9/100\n",
      "2049/2049 [==============================] - 0s 212us/step - loss: 0.1514 - accuracy: 0.9610\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.95949 to 0.96096, saving model to best-model.hdf5\n",
      "Epoch 10/100\n",
      "2049/2049 [==============================] - 0s 213us/step - loss: 0.0987 - accuracy: 0.9717\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.96096 to 0.97169, saving model to best-model.hdf5\n",
      "Epoch 11/100\n",
      "2049/2049 [==============================] - 0s 214us/step - loss: 0.0514 - accuracy: 0.9790\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.97169 to 0.97901, saving model to best-model.hdf5\n",
      "Epoch 12/100\n",
      "2049/2049 [==============================] - 0s 218us/step - loss: 0.0402 - accuracy: 0.9878\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.97901 to 0.98780, saving model to best-model.hdf5\n",
      "Epoch 13/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0320 - accuracy: 0.9922\n",
      "\n",
      "Epoch 00013: accuracy improved from 0.98780 to 0.99219, saving model to best-model.hdf5\n",
      "Epoch 14/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0253 - accuracy: 0.9922\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.99219\n",
      "Epoch 15/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.1280 - accuracy: 0.9693\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.99219\n",
      "Epoch 16/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.4570 - accuracy: 0.8956\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.99219\n",
      "Epoch 17/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.4202 - accuracy: 0.8921\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.99219\n",
      "Epoch 18/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.5525 - accuracy: 0.8526\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.99219\n",
      "Epoch 19/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.4945 - accuracy: 0.8814\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.99219\n",
      "Epoch 20/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.2235 - accuracy: 0.9283\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.99219\n",
      "Epoch 21/100\n",
      "2049/2049 [==============================] - 0s 218us/step - loss: 0.1152 - accuracy: 0.9619\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.99219\n",
      "Epoch 22/100\n",
      "2049/2049 [==============================] - 0s 221us/step - loss: 0.1246 - accuracy: 0.9605\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.99219\n",
      "Epoch 23/100\n",
      "2049/2049 [==============================] - 0s 215us/step - loss: 0.1589 - accuracy: 0.9536\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.99219\n",
      "Epoch 24/100\n",
      "2049/2049 [==============================] - 0s 212us/step - loss: 0.1411 - accuracy: 0.9566\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.99219\n",
      "Epoch 25/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0969 - accuracy: 0.9688\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.99219\n",
      "Epoch 26/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0632 - accuracy: 0.9790\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.99219\n",
      "Epoch 27/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.2498 - accuracy: 0.9273\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.99219\n",
      "Epoch 28/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.5272 - accuracy: 0.8673\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.99219\n",
      "Epoch 29/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.3931 - accuracy: 0.8897\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.99219\n",
      "Epoch 30/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.2763 - accuracy: 0.9297\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.99219\n",
      "Epoch 31/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.2890 - accuracy: 0.9151\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.99219\n",
      "Epoch 32/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1814 - accuracy: 0.9483\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.99219\n",
      "Epoch 33/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.1679 - accuracy: 0.9512\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.99219\n",
      "Epoch 34/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1225 - accuracy: 0.9624\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.99219\n",
      "Epoch 35/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1096 - accuracy: 0.9693\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.99219\n",
      "Epoch 36/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.1009 - accuracy: 0.9741\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.99219\n",
      "Epoch 37/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1001 - accuracy: 0.9746\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.99219\n",
      "Epoch 38/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.2764 - accuracy: 0.9366\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.99219\n",
      "Epoch 39/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.7382 - accuracy: 0.8570\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.99219\n",
      "Epoch 40/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.4464 - accuracy: 0.8926\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.99219\n",
      "Epoch 41/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.4772 - accuracy: 0.8814\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.99219\n",
      "Epoch 42/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.3744 - accuracy: 0.9024\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.99219\n",
      "Epoch 43/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.2582 - accuracy: 0.9327\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.99219\n",
      "Epoch 44/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.3153 - accuracy: 0.9165\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.99219\n",
      "Epoch 45/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.2771 - accuracy: 0.9258\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.99219\n",
      "Epoch 46/100\n",
      "2049/2049 [==============================] - 0s 216us/step - loss: 0.2103 - accuracy: 0.9444\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.99219\n",
      "Epoch 47/100\n",
      "2049/2049 [==============================] - 0s 227us/step - loss: 0.1831 - accuracy: 0.9541\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.99219\n",
      "Epoch 48/100\n",
      "2049/2049 [==============================] - 0s 214us/step - loss: 0.1291 - accuracy: 0.9673\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.99219\n",
      "Epoch 49/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1129 - accuracy: 0.9649\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.99219\n",
      "Epoch 50/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0755 - accuracy: 0.9790\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.99219\n",
      "Epoch 51/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.0707 - accuracy: 0.9776\n",
      "\n",
      "Epoch 00051: accuracy did not improve from 0.99219\n",
      "Epoch 52/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.0690 - accuracy: 0.9780\n",
      "\n",
      "Epoch 00052: accuracy did not improve from 0.99219\n",
      "Epoch 53/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.0806 - accuracy: 0.9805\n",
      "\n",
      "Epoch 00053: accuracy did not improve from 0.99219\n",
      "Epoch 54/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0605 - accuracy: 0.9800\n",
      "\n",
      "Epoch 00054: accuracy did not improve from 0.99219\n",
      "Epoch 55/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.0679 - accuracy: 0.9771\n",
      "\n",
      "Epoch 00055: accuracy did not improve from 0.99219\n",
      "Epoch 56/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0689 - accuracy: 0.9785\n",
      "\n",
      "Epoch 00056: accuracy did not improve from 0.99219\n",
      "Epoch 57/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0902 - accuracy: 0.9707\n",
      "\n",
      "Epoch 00057: accuracy did not improve from 0.99219\n",
      "Epoch 58/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.1307 - accuracy: 0.9634\n",
      "\n",
      "Epoch 00058: accuracy did not improve from 0.99219\n",
      "Epoch 59/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.3618 - accuracy: 0.9087\n",
      "\n",
      "Epoch 00059: accuracy did not improve from 0.99219\n",
      "Epoch 60/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.3090 - accuracy: 0.9195\n",
      "\n",
      "Epoch 00060: accuracy did not improve from 0.99219\n",
      "Epoch 61/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1741 - accuracy: 0.9507\n",
      "\n",
      "Epoch 00061: accuracy did not improve from 0.99219\n",
      "Epoch 62/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.2361 - accuracy: 0.9278\n",
      "\n",
      "Epoch 00062: accuracy did not improve from 0.99219\n",
      "Epoch 63/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.3221 - accuracy: 0.9229\n",
      "\n",
      "Epoch 00063: accuracy did not improve from 0.99219\n",
      "Epoch 64/100\n",
      "2049/2049 [==============================] - 0s 212us/step - loss: 0.1973 - accuracy: 0.9458\n",
      "\n",
      "Epoch 00064: accuracy did not improve from 0.99219\n",
      "Epoch 65/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.1506 - accuracy: 0.9649\n",
      "\n",
      "Epoch 00065: accuracy did not improve from 0.99219\n",
      "Epoch 66/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.1221 - accuracy: 0.9693\n",
      "\n",
      "Epoch 00066: accuracy did not improve from 0.99219\n",
      "Epoch 67/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.0759 - accuracy: 0.9751\n",
      "\n",
      "Epoch 00067: accuracy did not improve from 0.99219\n",
      "Epoch 68/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0760 - accuracy: 0.9785\n",
      "\n",
      "Epoch 00068: accuracy did not improve from 0.99219\n",
      "Epoch 69/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.0640 - accuracy: 0.9771\n",
      "\n",
      "Epoch 00069: accuracy did not improve from 0.99219\n",
      "Epoch 70/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0555 - accuracy: 0.9810\n",
      "\n",
      "Epoch 00070: accuracy did not improve from 0.99219\n",
      "Epoch 71/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0425 - accuracy: 0.9873\n",
      "\n",
      "Epoch 00071: accuracy did not improve from 0.99219\n",
      "Epoch 72/100\n",
      "2049/2049 [==============================] - 0s 224us/step - loss: 0.0473 - accuracy: 0.9893\n",
      "\n",
      "Epoch 00072: accuracy did not improve from 0.99219\n",
      "Epoch 73/100\n",
      "2049/2049 [==============================] - 0s 215us/step - loss: 0.0372 - accuracy: 0.9849\n",
      "\n",
      "Epoch 00073: accuracy did not improve from 0.99219\n",
      "Epoch 74/100\n",
      "2049/2049 [==============================] - 0s 217us/step - loss: 0.0422 - accuracy: 0.9878\n",
      "\n",
      "Epoch 00074: accuracy did not improve from 0.99219\n",
      "Epoch 75/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.0258 - accuracy: 0.9927\n",
      "\n",
      "Epoch 00075: accuracy improved from 0.99219 to 0.99268, saving model to best-model.hdf5\n",
      "Epoch 76/100\n",
      "2049/2049 [==============================] - 0s 213us/step - loss: 0.0439 - accuracy: 0.9839\n",
      "\n",
      "Epoch 00076: accuracy did not improve from 0.99268\n",
      "Epoch 77/100\n",
      "2049/2049 [==============================] - 0s 224us/step - loss: 0.0832 - accuracy: 0.9800\n",
      "\n",
      "Epoch 00077: accuracy did not improve from 0.99268\n",
      "Epoch 78/100\n",
      "2049/2049 [==============================] - 0s 215us/step - loss: 0.0798 - accuracy: 0.9722\n",
      "\n",
      "Epoch 00078: accuracy did not improve from 0.99268\n",
      "Epoch 79/100\n",
      "2049/2049 [==============================] - 1s 259us/step - loss: 0.0765 - accuracy: 0.9810\n",
      "\n",
      "Epoch 00079: accuracy did not improve from 0.99268\n",
      "Epoch 80/100\n",
      "2049/2049 [==============================] - 0s 233us/step - loss: 0.0739 - accuracy: 0.9810\n",
      "\n",
      "Epoch 00080: accuracy did not improve from 0.99268\n",
      "Epoch 81/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0641 - accuracy: 0.9829\n",
      "\n",
      "Epoch 00081: accuracy did not improve from 0.99268\n",
      "Epoch 82/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.0457 - accuracy: 0.9893\n",
      "\n",
      "Epoch 00082: accuracy did not improve from 0.99268\n",
      "Epoch 83/100\n",
      "2049/2049 [==============================] - 0s 220us/step - loss: 0.0240 - accuracy: 0.9927\n",
      "\n",
      "Epoch 00083: accuracy did not improve from 0.99268\n",
      "Epoch 84/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.0635 - accuracy: 0.9819\n",
      "\n",
      "Epoch 00084: accuracy did not improve from 0.99268\n",
      "Epoch 85/100\n",
      "2049/2049 [==============================] - 0s 222us/step - loss: 0.1157 - accuracy: 0.9732\n",
      "\n",
      "Epoch 00085: accuracy did not improve from 0.99268\n",
      "Epoch 86/100\n",
      "2049/2049 [==============================] - 0s 224us/step - loss: 0.0885 - accuracy: 0.9722\n",
      "\n",
      "Epoch 00086: accuracy did not improve from 0.99268\n",
      "Epoch 87/100\n",
      "2049/2049 [==============================] - 0s 214us/step - loss: 0.0640 - accuracy: 0.9805\n",
      "\n",
      "Epoch 00087: accuracy did not improve from 0.99268\n",
      "Epoch 88/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.0765 - accuracy: 0.9780\n",
      "\n",
      "Epoch 00088: accuracy did not improve from 0.99268\n",
      "Epoch 89/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0607 - accuracy: 0.9844\n",
      "\n",
      "Epoch 00089: accuracy did not improve from 0.99268\n",
      "Epoch 90/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.0450 - accuracy: 0.9839\n",
      "\n",
      "Epoch 00090: accuracy did not improve from 0.99268\n",
      "Epoch 91/100\n",
      "2049/2049 [==============================] - 0s 210us/step - loss: 0.0434 - accuracy: 0.9873\n",
      "\n",
      "Epoch 00091: accuracy did not improve from 0.99268\n",
      "Epoch 92/100\n",
      "2049/2049 [==============================] - 0s 218us/step - loss: 0.0509 - accuracy: 0.9839\n",
      "\n",
      "Epoch 00092: accuracy did not improve from 0.99268\n",
      "Epoch 93/100\n",
      "2049/2049 [==============================] - 0s 211us/step - loss: 0.1323 - accuracy: 0.9693\n",
      "\n",
      "Epoch 00093: accuracy did not improve from 0.99268\n",
      "Epoch 94/100\n",
      "2049/2049 [==============================] - 0s 226us/step - loss: 0.1916 - accuracy: 0.9527\n",
      "\n",
      "Epoch 00094: accuracy did not improve from 0.99268\n",
      "Epoch 95/100\n",
      "2049/2049 [==============================] - 0s 218us/step - loss: 0.1714 - accuracy: 0.9644\n",
      "\n",
      "Epoch 00095: accuracy did not improve from 0.99268\n",
      "Epoch 96/100\n",
      "2049/2049 [==============================] - 0s 217us/step - loss: 0.3854 - accuracy: 0.9248\n",
      "\n",
      "Epoch 00096: accuracy did not improve from 0.99268\n",
      "Epoch 97/100\n",
      "2049/2049 [==============================] - 0s 208us/step - loss: 0.3098 - accuracy: 0.9361\n",
      "\n",
      "Epoch 00097: accuracy did not improve from 0.99268\n",
      "Epoch 98/100\n",
      "2049/2049 [==============================] - 0s 212us/step - loss: 0.3085 - accuracy: 0.9429\n",
      "\n",
      "Epoch 00098: accuracy did not improve from 0.99268\n",
      "Epoch 99/100\n",
      "2049/2049 [==============================] - 0s 215us/step - loss: 0.3843 - accuracy: 0.9322\n",
      "\n",
      "Epoch 00099: accuracy did not improve from 0.99268\n",
      "Epoch 100/100\n",
      "2049/2049 [==============================] - 0s 209us/step - loss: 0.5025 - accuracy: 0.9156\n",
      "\n",
      "Epoch 00100: accuracy did not improve from 0.99268\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size=256, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8200, 25, 25, 16, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8200, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.99      0.98      0.98       664\n",
      "           3       0.96      1.00      0.98       190\n",
      "           4       0.98      1.00      0.99       386\n",
      "           5       0.98      0.98      0.98       584\n",
      "           6       1.00      1.00      1.00        22\n",
      "           7       1.00      1.00      1.00       382\n",
      "           8       0.80      1.00      0.89        16\n",
      "           9       0.97      1.00      0.98       778\n",
      "          10       0.99      0.97      0.98      1964\n",
      "          11       0.98      0.96      0.97       475\n",
      "          12       1.00      1.00      1.00       164\n",
      "          13       0.98      1.00      0.99      1012\n",
      "          14       0.98      1.00      0.99       309\n",
      "          15       0.89      0.97      0.93        74\n",
      "\n",
      "    accuracy                           0.98      8200\n",
      "   macro avg       0.97      0.99      0.98      8200\n",
      "weighted avg       0.98      0.98      0.98      8200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    "\n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                        'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200/8200 [==============================] - 1s 155us/step\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)\n",
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"classification_report.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize\n",
    "numComponents = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= applyLDA(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"predictions.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
